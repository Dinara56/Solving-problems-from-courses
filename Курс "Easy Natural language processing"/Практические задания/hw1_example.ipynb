{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMmjn1KpCyiq"
   },
   "source": [
    "# Задача 1\n",
    "\n",
    "\n",
    "В первой задаче необходимо оценить вероятность наличия в объявлении контактной информации. \n",
    "Результатом работы модели является `pd.DataFrame` с колонками:\n",
    "* `index`: `int`, положение записи в файле;\n",
    "* `prediction`: `float` от 0 до 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOtIN61qTcLz"
   },
   "source": [
    "# Решение\n",
    "## Импорт данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В этом задании вам предстоит реализовать решение для поиска контактов в объявлениях\n",
    "- Таргет `is_bad`. Если `is_bad = 1` - контакты в объявлении есть, иначе нет\n",
    "- В `train.csv` разметка может быть неточная\n",
    "- Задача показать результат **ROC AUC >= 0.8**\n",
    "- ROC AUC будет **усредняться по каждой категории**: оценка сначала в разрезе каждой категории, а потом усреднение\n",
    "- **ВАЖНО:** На платформе установлены следующие библиотеки (необходимо ограничиться ими):\n",
    "\n",
    "```\n",
    "joblib==1.3.2\n",
    "numpy==1.23.5\n",
    "pandas==2.2.2\n",
    "scipy==1.11.4\n",
    "scikit-learn==1.4.2\n",
    "lightgbm==4.3.0'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поля в тренировочном `train.csv` и проверочном датасетах:\n",
    "* `title` - заголовок,\n",
    "* `description` - описание,\n",
    "* `subcategory` - подкатегория,\n",
    "* `category` - категория,\n",
    "* `price` - цена,\n",
    "* `region` - регион,\n",
    "* `city` - город,\n",
    "* `datetime_submitted` - дата размещения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "HoJxofkV3N5y",
    "outputId": "164e9d46-b0df-415e-f1fc-827918642fbe"
   },
   "outputs": [],
   "source": [
    "# ваш импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URxjUkuW3GcJ"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOCDzPSDCg-S"
   },
   "source": [
    "## Преобразование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Код с кастомными классами, а также со всеми необходимыми библиотеками, необходимо сохранить в отдельном файле с разширением *.py!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь должен быть ваш кастомный класс для дополнительной обработки данных\n",
    "# например, хотите использовать регулярные выражения. В результате обработк при помощи такого\n",
    "# класса получаете ЧИСЛЕННОЕ значение\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "CONSTANT = # константны, можно сюда писать паттерны - опционально\n",
    "\n",
    "class YourClassNumber(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, pattern ** kwargs):\n",
    "        self.pattern = pattern\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def preprocessing(self, data: str):\n",
    "        ###\n",
    "        return #\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = csr_matrix(X.apply(self.preprocessing)).T\n",
    "        return result\n",
    "\n",
    "    def get_feature_names(self):  # опционально\n",
    "        return #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь должен быть ваш кастомный класс для дополнительной обработки данных\n",
    "# например, хотите обработать текст и удалить лишние символы. В результате обработк при помощи такого\n",
    "# класса получаете ТЕКСТОВЫЕ признаки\n",
    "\n",
    "\n",
    "class YourClassText(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def preprocessing(self, s):\n",
    "        #\n",
    "        return  #\n",
    "\n",
    "    def to_desc(self, s):\n",
    "        return self.preprocessing(s)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(self.to_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты построим pipline, чтобы далее можно было удобно применять на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "SPLIT = 0.2\n",
    "RANDOM_STATE = 10\n",
    "\n",
    "# Создаем полный pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    # процесс обработки фичей\n",
    "    ('preprocessing', ColumnTransformer(\n",
    "        [\n",
    "            # обработка числовых значений - опционально\n",
    "            ('numerical', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy=....)),\n",
    "                ('scaler', StandardScaler())]), ['признак']), \n",
    "            # обработка категориальных значений - опционально\n",
    "            ('categorical', OneHotEncoder(handle_unknown='ignore', drop=...), ['признак1', 'признак2', ...]),\n",
    "            # обработка тестовых признаков -> получаем числа - опционально\n",
    "            ('description_regex', YourClassNumber(pattern= CONSTANT ...), 'description'),\n",
    "            # обработка тестовых признаков -> сначала получаем строки, потом переводим в числа - опционально\n",
    "            # поэтому строим для этого общий пайплан, так как модели в требовании не умеют работать\n",
    "            # с текстовыми данными - опционально\n",
    "            ('description', Pipeline([\n",
    "                ('preprocessor', FunctionTransformer(YourClassText().transform)),\n",
    "                # любой векторизатор, например TF-IDF\n",
    "                ('tfidf', TfidfVectorizer(....))]), 'description'),\n",
    "            # любой векторизатор, например TF-IDF - опционально\n",
    "            ('title_tfidf', TfidfVectorizer(), 'title'),\n",
    "        ],\n",
    "        remainder=...\n",
    "    )),\n",
    "    # Ваш классификатор, например LogReg\n",
    "    ('model', LogisticRegression(....))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['is_bad'])\n",
    "y = train['is_bad']\n",
    "\n",
    "# показан один из способов разбиения данных, вы можете разбить так, как считаете нужным\n",
    "# либо даже обучать на всей выборке\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=SPLIT,\n",
    "                                                    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты\n",
    "\n",
    "Посмотрим на значение метрик в каждой из категории, а также на среднее значение `ROC AUC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(full_pipeline.predict_proba(X_test)[:, 1],\n",
    "                   index=y_test.index)\n",
    "calegories = np.unique(X_test.category.tolist())\n",
    "\n",
    "roc_auc_category = {}\n",
    "\n",
    "for cat in calegories:\n",
    "    idx = X_test[X_test.category == cat].index\n",
    "    roc_auc = roc_auc_score(y_test[idx], y_pred[idx])\n",
    "    roc_auc_category[cat] = roc_auc\n",
    "    print(f'{cat} - {roc_auc:0.2f}')\n",
    "\n",
    "print(f'\\nROC_AUC = {np.mean(list(roc_auc_category.values())):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(full_pipeline, 'my_solve.joblib') "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
